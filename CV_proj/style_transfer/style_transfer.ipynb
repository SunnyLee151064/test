{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms,models\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "import copy \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torchvision\\transforms\\transforms.py:285: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  warnings.warn(\"The use of the transforms.Scale transform is deprecated, \" +\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.Scale([224,224]),\n",
    "                               transforms.ToTensor()])\n",
    "\n",
    "def  loadimg(path = None):\n",
    "    img = Image.open(path)\n",
    "    img = transform(img)\n",
    "    img = img.unsqueeze(0)\n",
    "    return img\n",
    "    \n",
    "ToPIL = torchvision.transforms.ToPILImage()\n",
    "    \n",
    "def img_show(img, title = None):\n",
    "    img = img.clone().cpu()\n",
    "    img = img.view(3,224,224)\n",
    "    img = ToPIL(img)\n",
    "\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#! 定义内容Loss，风格Loss以及Gram矩阵\n",
    "class Content_loss(torch.nn.Module):\n",
    "    def __init__(self, weight, target):\n",
    "        super(Content_loss, self).__init__()\n",
    "        self.weight = weight\n",
    "        self.target = target.detach()*weight\n",
    "        self.loss_fn = torch.nn.MSELoss()\n",
    "        \n",
    "    def forward(self, input):\n",
    "        self.loss = self.loss_fn(input*self.weight, self.target)\n",
    "        self.output = input\n",
    "        return self.output\n",
    "        \n",
    "    def backward(self):\n",
    "        self.loss.backward(retain_graph = True)\n",
    "        return self.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gram_matrix(torch.nn.Module):\n",
    "    def forward(self, input):\n",
    "        a,b,c,d = input.size()\n",
    "        feature = input.view(a*b, c*d)\n",
    "        gram = torch.mm(feature, feature.t())\n",
    "        return gram.div(a*b*c*d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Style_loss(torch.nn.Module):\n",
    "    def __init__(self, weight, target):\n",
    "        super(Style_loss, self).__init__()\n",
    "        self.weight = weight\n",
    "        self.target = target.detach()*weight\n",
    "        self.loss_fn = torch.nn.MSELoss()\n",
    "        self.gram = gram_matrix()\n",
    "        \n",
    "    def forward(self, input):\n",
    "        self.output = input.clone()\n",
    "        self.G = self.gram(input)\n",
    "        self.G.mul_(self.weight)\n",
    "        self.loss = self.loss_fn(self.G, self.target)\n",
    "        return self.output\n",
    "    def backward(self):\n",
    "        self.loss.backward(retain_graph = True)\n",
    "        return self.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "cnn = models.vgg16(pretrained=True).features\n",
    "if use_gpu:\n",
    "    cnn = cnn.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (Conv_1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (style_loss_1): Style_loss(\n",
      "    (loss_fn): MSELoss()\n",
      "    (gram): gram_matrix()\n",
      "  )\n",
      "  (Relu_1): ReLU(inplace=True)\n",
      "  (Conv_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (style_loss_2): Style_loss(\n",
      "    (loss_fn): MSELoss()\n",
      "    (gram): gram_matrix()\n",
      "  )\n",
      "  (Relu_2): ReLU(inplace=True)\n",
      "  (MaxPool_3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (Conv_3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (style_loss_3): Style_loss(\n",
      "    (loss_fn): MSELoss()\n",
      "    (gram): gram_matrix()\n",
      "  )\n",
      "  (Relu_3): ReLU(inplace=True)\n",
      "  (Conv_4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (style_loss_4): Style_loss(\n",
      "    (loss_fn): MSELoss()\n",
      "    (gram): gram_matrix()\n",
      "  )\n",
      "  (Relu_4): ReLU(inplace=True)\n",
      "  (MaxPool_5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (Conv_5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (content_loss_5): Content_loss(\n",
      "    (loss_fn): MSELoss()\n",
      "  )\n",
      "  (style_loss_5): Style_loss(\n",
      "    (loss_fn): MSELoss()\n",
      "    (gram): gram_matrix()\n",
      "  )\n",
      "  (Relu_5): ReLU(inplace=True)\n",
      "  (Conv_6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (content_loss_6): Content_loss(\n",
      "    (loss_fn): MSELoss()\n",
      "  )\n",
      "  (Relu_6): ReLU(inplace=True)\n",
      "  (Conv_7): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (Relu_7): ReLU(inplace=True)\n",
      "  (MaxPool_8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (Conv_8): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (Relu_8): ReLU(inplace=True)\n",
      "  (Conv_9): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (Relu_9): ReLU(inplace=True)\n",
      "  (Conv_10): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (Relu_10): ReLU(inplace=True)\n",
      "  (MaxPool_11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (Conv_11): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (Relu_11): ReLU(inplace=True)\n",
      "  (Conv_12): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (Relu_12): ReLU(inplace=True)\n",
      "  (Conv_13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (Relu_13): ReLU(inplace=True)\n",
      "  (MaxPool_14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "content_layer = [\"Conv_5\",\"Conv_6\"]\n",
    "\n",
    "style_layer = [\"Conv_1\", \"Conv_2\", \"Conv_3\", \"Conv_4\", \"Conv_5\"]\n",
    "\n",
    "content_img = loadimg(\"./source.jpg\")\n",
    "content_img = Variable(content_img).cuda()\n",
    "style_img = loadimg(\"./model.jpg\")\n",
    "style_img = Variable(style_img).cuda()\n",
    "\n",
    "content_losses = []\n",
    "style_losses = []\n",
    "\n",
    "conten_weight = 1\n",
    "style_weight = 1000\n",
    "\n",
    "new_model = torch.nn.Sequential()\n",
    "\n",
    "model = copy.deepcopy(cnn)\n",
    "\n",
    "gram = gram_matrix()\n",
    "\n",
    "if use_gpu:\n",
    "    new_model = new_model.cuda()\n",
    "    gram = gram.cuda()\n",
    "\n",
    "index = 1\n",
    "for layer in list(model):\n",
    "    if isinstance(layer, torch.nn.Conv2d):\n",
    "        name = \"Conv_\"+str(index)\n",
    "        new_model.add_module(name, layer)\n",
    "        if name in content_layer:\n",
    "            target = new_model(content_img).clone()\n",
    "            content_loss = Content_loss(conten_weight, target)\n",
    "            new_model.add_module(\"content_loss_\"+str(index), content_loss)\n",
    "            content_losses.append(content_loss)\n",
    "            \n",
    "        if name in style_layer:\n",
    "            target = new_model(style_img).clone()\n",
    "            target = gram(target)\n",
    "            style_loss = Style_loss(style_weight, target)\n",
    "            new_model.add_module(\"style_loss_\"+str(index), style_loss)\n",
    "            style_losses.append(style_loss)\n",
    "            \n",
    "    if isinstance(layer, torch.nn.ReLU):\n",
    "        name = \"Relu_\"+str(index)\n",
    "        new_model.add_module(name, layer)\n",
    "        index = index+1\n",
    "            \n",
    "    if isinstance(layer, torch.nn.MaxPool2d):\n",
    "        name = \"MaxPool_\"+str(index)\n",
    "        new_model.add_module(name, layer)\n",
    "\n",
    "print(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = content_img.clone()\n",
    "\n",
    "parameter = torch.nn.Parameter(input_img.data)\n",
    "optimizer = torch.optim.LBFGS([parameter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16604\\3054093994.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     87\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\optim\\lbfgs.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    435\u001b[0m                     \u001b[1;31m# no use to re-evaluate that function here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m                     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 437\u001b[1;33m                         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    438\u001b[0m                     \u001b[0mflat_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gather_flat_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m                     \u001b[0mopt_cond\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mflat_grad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mtolerance_grad\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16604\\3054093994.py\u001b[0m in \u001b[0;36mclosure\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m50\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m             print('{} Style Loss : {:4f} Content Loss: {:4f}'.format(run[0],\n\u001b[1;32m---> 21\u001b[1;33m                  style_score.data[0], content_score.data[0])) \n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mstyle_score\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mcontent_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number"
     ]
    }
   ],
   "source": [
    "n_epoch = 1000\n",
    "\n",
    "run = [0]\n",
    "while run[0] <= n_epoch:\n",
    "\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        style_score = 0\n",
    "        content_score = 0\n",
    "        parameter.data.clamp_(0,1)\n",
    "        new_model(parameter)\n",
    "        for sl in style_losses:\n",
    "            style_score += sl.backward()\n",
    "        \n",
    "        for cl in content_losses:\n",
    "            content_score += cl.backward()\n",
    "        \n",
    "        run[0] += 1 \n",
    "        if run[0] % 50 == 0:\n",
    "            print('{} Style Loss : {:4f} Content Loss: {:4f}'.format(run[0],\n",
    "                 style_score.data[0], content_score.data[0])) \n",
    "\n",
    "        return style_score+content_score\n",
    "    \n",
    "\n",
    "\n",
    "    optimizer.step(closure)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0b44c525ca95e5dbf893da2282eb3ec3f420cb9fa59d94f9af90ca833dc1a37c"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
